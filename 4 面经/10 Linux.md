[TOC]

```shell
cat -n/ more 									# 都用来查看文件，cat看小文件，全部显示，more看大文件，分屏显示
head -n 200 filename 							# 查看文本文件头部n行,200可替换为任一数字
tail -n 200 filename 							# 查看文本文件末尾n行, 200可替换为任一数字

grep "search content" filename1					# 搜索某个文件里面是否包含字符串
wc -l filename									# 查看文本文件行数
find [路径] -name "*.py"
sed -i 's/查找的字符串/替换的字符串/' 文件		   # 替换文件中每行第一次出现的字符串
sed -i 's/查找的字符串/替换的字符串/g' 文件		   # 替换文件中所有出现过的字符串

echo XXX > 123.txt  /  echo XXX >> 123.txt 		# >会覆盖，>>是追加 
scp -P port user@XXX:Desktop/123.txt 123.txt 	# 远程复制，-r可以复制文件夹
scp -r demp user@XXX:Desktop
#########################################################################
ps au											# a查看全部进程，u显示进程详细状态
ps -ef|grep 进程ID
top 											# 动态查看进程，退出需要按q
top -H -p <PID> 								# 查看某个进程（PID）的所有线程
netstat -nap | grep 5672						# 监听5672接口
kill -9 进程号
#########################################################################
ln -s 被链接的源文件 链接文件	 					 # 源文件要用绝对目录
tar -zcvf 打包文件.tar.gz 被打包的文件、目录			# z换成j，则为.tar.bz2
tar -zxvf 打包文件.tar.gz -C 目标路径
```



### 1 为什么需要区分内核空间与用户空间？

> ​		Linux虚拟内存的大小为2^32（在32位的x86机器上），内核将这4G字节的空间分为两部分。最高的1G字节（从虚地址0xC0000000到0xFFFFFFFF）供内核使用，称为“**内核空间**”。而较低的3G字节（从虚地址0x00000000到0xBFFFFFFF），供各个进程使用，称为“**用户空间**”。因为每个进程可以通过系统调用进入内核，因此，Linux内核空间由系统内的所有进程共享。

**一定程度上的冲突避免**

​		于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟地址空间(也叫虚拟内存).

​		每个进程有各自的私有用户空间（0～3G），这个空间对系统中的其他进程是不可见的。最高的1GB内核空间则为所有进程以及内核所共享。另外，进程的“用户空间”也叫“地址空间”。

​		用户空间不是进程共享的，而是进程隔离的。每个进程最大都可以有3GB的用户空间。一个进程对其中一个地址的访问，与其它进程对于同一地址的访问绝不冲突。比如，一个进程从其用户空间的地址0x1234ABCD处可以读出整数8，而另外一个进程从其用户空间的地址0x1234ABCD处可以读出整数20，这取决于进程自身的逻辑。



### 2 线上服务器的cpu使用达到100%了，如何排查、定位和解决该问题？

> 线上服务器的cpu使用达到100%了，如何排查、定位和解决该问题？

1. `top`+P

2. 定位哪段代码导致的cpu过高

	printf“%x\n”16872，把线程pid 转换成16进制，比如41e8

	`jstack 43987 I grep‘0x41e8’-C5-color`
	这个就是用jstack打印进程的堆栈信息，而且通过grep那个线程的16进制的pid，找到那个线程相关的东西，这个时候就可以在打印出的代码里，看到是哪个类的哪个方法导致的这个cpu 100%的问题



### 3 强杀进程

`ps aux`，看看STAT那一栏，如果是z，那么就是zombie状态的僵尸进程

`ps -ef I grep 僵尸进程id`，可以找到父进程id



### 4 服务器存储空间快满了

1. `df -h`，先看看磁盘使用的情况，然后就是到你的系统部署的地方，一般就是tomcat/spring boot 下的日志去看看，如果过多，就删除掉一些日志就行了，自己注意让tomcat或者nginx之类的日志输出，按天切割，这样你还可以写个shell脚本定期删除7天以前的日志
2. 要是不行，那就：`find/-size+100M | xargs ls -lh`，找找大于100m的文件，但是如果有大量的小文件，那么这样是不行的
3. 或者是用：`du-h>fs_du.log`，看看各个目录占用的磁盘空间大小，看看是不是哪个目录有大量的小文件

