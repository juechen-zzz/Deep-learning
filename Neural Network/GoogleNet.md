# GoogleNet

## Abstract

* 这种架构的主要**特点**是在网络中对计算资源使用的优化提升
* 为了优化质量，架构决策基于Hebbian原则和多尺度处理的初衷
* 22层深的网络



## Introduction

* 在目标分类和检测性能上，这几年有了很大提升，但并不仅仅是因为更强大的硬件、更多的数据和更大的模型，而主要是因为有了一系列更好的想法、算法和网络架构
* 在物体检测方面，最大的收益并非来自大而深的网络的自然应用，而是来自深层架构和经典计算机视觉的协同作用，如Girshick等的R-CNN算法。
* 另一个值得注意的因素是，随着移动和嵌入式计算的不断发展，我们的算法效率 - 尤其是它们的功耗和内存使用 - -变得越来越重要，本文中提出的导致深层结构设计的考虑因素包括这个因素，而不是纯粹固定精度数字
* 本文中的深度有两层含义：
  * 首先，在某种意义上，我们以“初始模块”的形式引入了一种新的组织层次
  * 并且更直接地意味着增加了网络深度。



## Related Work

* 从LeNet-5 开始，卷积神经网络（CNN）通常具有标准结构 - 堆叠卷积层（可选地随后是正则化和最大池化）之后是一个或多个全连接层。这种基本设计的变体在图像分类文献中很普遍，并且迄今为止在MNIST，CIFAR和最显着的ImageNet分类挑战上产生了最好的结果
* 尽管人们担心最大池化层会导致准确的空间信息丢失，但[9]的卷积网络架构也已经成功地用于局部化[9,14]，物体检测和人体姿势估计
* 使用了一系列不同尺寸的固定Gabor滤波器来处理多种尺度。然而，与[15]的固定2层深度模型相反，学习了Inception架构中的所有过滤器。此外，初始层重复多次，在GoogLeNet模型的情况下导致**22**层深度模型。
* 在我们的设置中，1×1卷积具有**双重目的**：最关键的是，它们主要用于降低计算瓶颈，以消除计算瓶颈，否则会限制我们网络的规模。这不仅可以增加深度，还可以增加网络的宽度，而不会显着降低性能。
* R-CNN将所有检测问题分解为**两个子问题**：利用颜色和纹理等低级线索，通过与类别无关的方式生成对象位置提议，以及使用CNN分类器识别这些位置的对象类别。这种两阶段方法利用了低水平线索的边界框分割的准确性，以及最先进的CNN的强大分类能力。我们在检测提交中采用了类似的通道，但是已经探索了两个阶段的增强功能，例如用于更高对象边界框召回的多框预测，以及用于更好地分类边界框提议的集合方法。



## Motivation and High Level Considerations

* 一般的考虑是加大网络结构，但是有两个主要**缺点**
  * 更大的尺寸意味着更多的参数，会使得模型更容易过拟合，尤其是当训练集中的标签样本数量有限的时候（需要人工分辨，例如狼和哈士奇）
  * 更大的网络意味着对计算能力的要求更高。例如，在深度视觉网络中，如果链接两个卷积层，则其滤波器数量的任何均匀增加导致计算的二次增加。如果无效地使用增加的容量（例如，如果大多数权重最终接近于零），则大部分计算被浪费。由于计算预算总是有限的，即使主要目标是提高性能质量，计算资源的有效分配也优于不加区别地增加规模
* 解决这两个问题的一个基本方法是引入稀疏性，并用稀疏层来代替全连接层，即使在卷积内也是如此。
* 如果数据集的概率分布可由大的，非常稀疏的深度神经网络表示，则可以通过分析前期层激活的相关统计数据和具有高度相关输出的聚类神经元来逐层构建最优网络拓扑。
* 大多数当前的视觉导向机器学习系统仅利用空间域中的稀疏性来实现对话。稀疏矩阵乘法有一个良好的实践办法是将稀疏矩阵聚类成相对密集的子矩阵
* Inception架构最初是作为一个案例研究，用于**评估复杂网络拓扑构造算法的假设输出**，该算法试图逼近[2]隐含的视觉网络稀疏结构，并通过密集，易于获得的组件来覆盖假设结果。尽管是一个高度投机的事业，但与基于[12]的参考网络相比，早期观察到了适度的增长。通过稍微调整，间隙变宽，并且在本地化和物体检测作为[6]和[5]的基础网络的背景下，Inception架构证明特别有用。



## Architectural Details

* Inception架构的主要思想是考虑如**何通过容易获得的密集组件来近似和覆盖卷积视觉网络的最佳局部稀疏结构**。
* Arora等[2]建议采用逐层构造，其中应该分析最后一层的相关统计数据，并将它们聚类成具有高相关性的单元组。这些聚类形成下一层的单元，并连接到前一层中的单元。我们假设来自较早层的每个单元对应于输入图像的某个区域，并且这些单元被分组为滤波器组。
* 使用大的卷积核在空间上会扩散更多的区域，而对应的聚类就会变少，聚类的数目随着卷积核增大而减少，为了避免这个问题，inception架构当前只使用1*1,3*3,5*5的滤波器大小，这个决策更多的是为了方便而不是必须的。 
* 将池化单元组合到一起就会面临更加明显的问题:他们输出滤波器数量等于上一阶段滤波器数量，每个阶段的跨越这就不可避免的会增加输出数量，在计算力需求急速增长的部分我们明智的应用**降维**和projections技术
* 1* 1卷积做compute reductions, 而不是计算3* 3或5* 5的卷积;除此之外，1*1卷积还可以用来矫正线性激活