# GoogleNet

## Abstract

* 这种架构的主要**特点**是在网络中对计算资源使用的优化提升
* 为了优化质量，架构决策基于Hebbian原则和多尺度处理的初衷
* 22层深的网络



## Introduction

* 在目标分类和检测性能上，这几年有了很大提升，但并不仅仅是因为更强大的硬件、更多的数据和更大的模型，而主要是因为有了一系列更好的想法、算法和网络架构
* 在物体检测方面，最大的收益并非来自大而深的网络的自然应用，而是来自深层架构和经典计算机视觉的协同作用，如Girshick等的R-CNN算法。
* 另一个值得注意的因素是，随着移动和嵌入式计算的不断发展，我们的算法效率 - 尤其是它们的功耗和内存使用 - -变得越来越重要，本文中提出的导致深层结构设计的考虑因素包括这个因素，而不是纯粹固定精度数字
* 本文中的深度有两层含义：
  * 首先，在某种意义上，我们以“初始模块”的形式引入了一种新的组织层次
  * 并且更直接地意味着增加了网络深度。



## Related Work

* 从LeNet-5 开始，卷积神经网络（CNN）通常具有标准结构 - 堆叠卷积层（可选地随后是正则化和最大池化）之后是一个或多个全连接层。这种基本设计的变体在图像分类文献中很普遍，并且迄今为止在MNIST，CIFAR和最显着的ImageNet分类挑战上产生了最好的结果
* 尽管人们担心最大池化层会导致准确的空间信息丢失，但[9]的卷积网络架构也已经成功地用于局部化[9,14]，物体检测和人体姿势估计
* 使用了一系列不同尺寸的固定Gabor滤波器来处理多种尺度。然而，与[15]的固定2层深度模型相反，学习了Inception架构中的所有过滤器。此外，初始层重复多次，在GoogLeNet模型的情况下导致**22**层深度模型。
* 在我们的设置中，1×1卷积具有**双重目的**：最关键的是，它们主要用于降低计算瓶颈，以消除计算瓶颈，否则会限制我们网络的规模。这不仅可以增加深度，还可以增加网络的宽度，而不会显着降低性能。
* R-CNN将所有检测问题分解为**两个子问题**：利用颜色和纹理等低级线索，通过与类别无关的方式生成对象位置提议，以及使用CNN分类器识别这些位置的对象类别。这种两阶段方法利用了低水平线索的边界框分割的准确性，以及最先进的CNN的强大分类能力。我们在检测提交中采用了类似的通道，但是已经探索了两个阶段的增强功能，例如用于更高对象边界框召回的多框预测，以及用于更好地分类边界框提议的集合方法。

