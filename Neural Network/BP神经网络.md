# BP神经网络

## 最小二乘法（LS算法）

​		是统计分析中常用的逼近计算的一种算法，是一种数学优化技术。其通过**最小化误差的平方和寻找数据的最佳函数匹配**，类似于**损失函数**。



## 梯度下降法

​	**缺点**：噪声较多，在计算过程中并不是都向着整体最优解的方向优化，往往可能只是一个局部最优解。



## ReLU函数 tf.nn.relu()

优点：

* 收敛快：对SGD的收敛有巨大的加速作用，可以看到对于达到阈值的数据其激活力度随数值的加大而增大，且呈现出一个线性关系
* 计算简单：算法较为简单，单纯一个值的输入输出不需要进行一系列的复杂计算，从而获得激活值
* 不易过拟合：一部分神经元在计算时如果有一个过大的梯度经过，那么次神经元的梯度会被强行设置为0， 而在整个其后的训练过程中这个神经元都不会被激活，这会导致数据多样化的丢失，但是也能防止过拟合



## Sigmoid函数 tf.nn.sigmoid()

